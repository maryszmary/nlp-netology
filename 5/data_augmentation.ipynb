{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sfuamkw28rgp"
   },
   "source": [
    "# Аугментация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89zDRG-jIdNB"
   },
   "source": [
    "В нашем примере данные были сбалансированными, а как работать с небалансированными данными. \n",
    "\n",
    "Рассмотрим задачу распознавания тональности твитов, взятых из [Twitter Sentimental Analysis challenge](https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/).\n",
    "\n",
    "Источник изложения: https://github.com/mabusalah/Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLKzWFu-QWAm"
   },
   "source": [
    "Получим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "5_WpbqWhk-a5",
    "outputId": "643d7706-ca10-42fb-dfad-42fa53966127"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/rxu4fud7xuyh7dv/test.csv\n",
    "# !wget https://www.dropbox.com/s/j6yh3xohvtqheqe/train_tweet.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ILRsSOuWJGFP",
    "outputId": "065acb35-235f-4ec4-bfc1-7eee32ed3589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: (33, 2) 33\n",
      "Training Set: (31962, 3) 31962\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(\"Test Set:\"% test.columns, test.shape, len(test))\n",
    "train = pd.read_csv('train_tweet.csv')\n",
    "print(\"Training Set:\"% train.columns, train.shape, len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sBtAsQDNJPXX",
    "outputId": "c0cb27b7-2a42-4457-9abf-c2363d03eef8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "XV-4lGQVJRc2",
    "outputId": "6587904f-01d2-4ad9-9f9b-72b53e585e8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xarXsO4DJU8Y"
   },
   "source": [
    "Итак, посмотрим, какой процент от общей выборки занимают позитивные и негативные примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eT7Rz3MNJTVP",
    "outputId": "591e736c-10da-4b4a-e312-d44d4fc362d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  92.98542018647143 %\n",
      "Negative:  7.014579813528565 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \", train.label.value_counts()[0]/len(train)*100,\"%\")\n",
    "print(\"Negative: \", train.label.value_counts()[1]/len(train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VB6Jaz-mJ1zR"
   },
   "source": [
    "93% vs. 7% - данные определенно несбалансированны, что, в свою очередь, негативно влияет на точность предсказания.\n",
    "Для начала поработаем с исходными данными и оценим точность классификации.\n",
    "Начнем с предобработки данных: уберем из твитов числа, html/xml-тэги, специальные символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCmZHO1kJfpP"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup #для работы с html/xml-тэгами\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter=PorterStemmer()\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "\n",
    "    words = tok.tokenize(lower_case)\n",
    "    \n",
    "    stem_sentence=[]\n",
    "    for word in words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    words=\"\".join(stem_sentence).strip()\n",
    "    return words\n",
    "\n",
    "nums = [0,len(train)]\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    clean_tweet_texts.append(tweet_cleaner(train['tweet'][i]))\n",
    "    \n",
    "nums = [0,len(test)]\n",
    "test_tweet_texts = []\n",
    "\n",
    "for i in range(nums[0],nums[1]):\n",
    "    test_tweet_texts.append(tweet_cleaner(test['tweet'][i])) \n",
    "    \n",
    "train_clean = pd.DataFrame(clean_tweet_texts,columns=['tweet'])\n",
    "train_clean['label'] = train.label\n",
    "train_clean['id'] = train.id\n",
    "test_clean = pd.DataFrame(test_tweet_texts,columns=['tweet'])\n",
    "test_clean['id'] = test.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkQ5fDVUM9EU"
   },
   "source": [
    "Разделим данные на обучающие и проверочные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, metrics, linear_model, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d23SW3-tMdKk"
   },
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train_clean['tweet'],train_clean['label'])\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tfj1ZjQANVSK"
   },
   "source": [
    "Рассчитаем TF-IDF признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNw9U1WnNKfq"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(train_clean['tweet'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIaiuRviW5pS"
   },
   "source": [
    "Попробуйте использовать обычный счетчик слов для извлечения признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vsr0wT4NW2LW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8TxxultNlOq"
   },
   "source": [
    "Точность в качестве метрики работает хорошо только на сбалансированных наборах данных, поэтому для оценки результатов работы  алгоритма будем использовать F1-метрику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx29ZstgNXqb"
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    predictions = classifier.predict(feature_vector_valid)    \n",
    "\n",
    "    return metrics.f1_score(valid_y,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YEjiEUDNrLj"
   },
   "source": [
    "Для начала обучим лог-регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BG3DifE-Nn-I",
    "outputId": "4607b633-686f-45c6-ca37-bce59ca23cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Baseline, WordLevel TFIDF:  0.5136612021857924\n"
     ]
    }
   ],
   "source": [
    "accuracyORIGINAL = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"Logistic regression Baseline, WordLevel TFIDF: \", accuracyORIGINAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0baBnaYN7a0"
   },
   "source": [
    "Как видно, результат оставляет желать лучшего.\n",
    "\n",
    "Что можно сделать с данными?\n",
    "\n",
    "Было бы неплохо как-то увеличить  количество негативных примеров, или же уменьшить количество положительных. Для этого существуют различные техники аугментации данных. \n",
    "В Python для этих целей есть библиотека imblearn (imbalanced-learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "F6zNqmnUN1WB",
    "outputId": "443b0e69-da50-423e-952a-2e7579987764"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, SMOTE, ADASYN, SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                    NearMiss, \n",
    "                                    InstanceHardnessThreshold,\n",
    "                                    CondensedNearestNeighbour,\n",
    "                                    EditedNearestNeighbours,\n",
    "                                    RepeatedEditedNearestNeighbours,\n",
    "                                    AllKNN,\n",
    "                                    NeighbourhoodCleaningRule,\n",
    "                                    OneSidedSelection,\n",
    "                                    TomekLinks)\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efoIi6euYMQs"
   },
   "source": [
    "Итак, в качестве инструментов для аугментации рассмотрим: under-sampling, over-sampling и их комбинацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqhD2dodYwJl"
   },
   "source": [
    "**Under-sampling** уравновешивает данные за счет уменьшения размера  превалирующего класса.\n",
    "Этот метод разумно использовать, когда количество данных достаточно велико, иначе есть риск остаться и вовсе без обучающих примеров.\n",
    "\n",
    "Итак, логика действия довольно проста: мы просто случайным образом убираем лишние экземпляры из превалирующего класса.\n",
    "\n",
    "Так как в нашем примере лишь 7% всех твитов имеют негативную окраску, уравновешивание позитивного набора с этими 7-ю процентами вряд ли обеспечит хороший результат.\n",
    "\n",
    "Попробуем..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AQVfIvf0aTrp",
    "outputId": "78df04f1-89b9-493e-8a54-76d10b33684f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regressio RUS, WordLevel TFIDF:  0.4744842562432139\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
    "rus_xtrain_tfidf, rus_train_y = rus.fit_sample(xtrain_tfidf, train_y)\n",
    "accuracyrus = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),rus_xtrain_tfidf, rus_train_y, xvalid_tfidf)\n",
    "print (\"Logistic regressio RUS, WordLevel TFIDF: \", accuracyrus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnwqxfGeaa9R"
   },
   "source": [
    "Действительно, все стало только хуже.\n",
    "\n",
    "Попробуем другие алгоритмы **under-sampling**.\n",
    "\n",
    "Например, **NearMiss**. Данный алгоритм выбирает, какие экземпляры нужно оставить в превалирующем классе на основании некоторых эвристик. Существует три варианта данного алгоритма:\n",
    "\n",
    "**NearMiss-1** оставляет те экземпляры из превалирующего класса, для которых среднее расстояние до *k* ближайших соседей из миноритарного класса будет наименьшим.\n",
    "\n",
    "**NearMiss-2** оставляет те экземпляры из превалирующего класса, для которых среднее расстояние до *k* самых дальних соседей из миноритарного класса будет наименьшим.\n",
    "\n",
    "**NearMiss-3** состоит из двух шагов: сначала, для каждого экземпляра из миноритарного класса выбирается *k* ближайших соседей из превалирующего класса, затем, из большего класса выбираются те экземпляры, для которых среднее расстояние до *k* ближайших соседей максимальное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "QSlgmHmOd9tU",
    "outputId": "34b209de-8b71-46d5-ab95-f35bbeb05c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression NearMiss(version= 1), WordLevel TFIDF:  0.25690140845070425\n",
      "Logistic regression NearMiss(version= 2), WordLevel TFIDF:  0.49223946784922396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/under_sampling/_prototype_selection/_nearmiss.py:194: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn('The number of the samples to be selected is larger'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression NearMiss(version= 3), WordLevel TFIDF:  0.2904228855721393\n"
     ]
    }
   ],
   "source": [
    "for sampler in (NearMiss(version=1),NearMiss(version=2),NearMiss(version=3)):\n",
    "    nm_xtrain_tfidf, nm_train_y = sampler.fit_sample(xtrain_tfidf, train_y)\n",
    "    accuracysm = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),nm_xtrain_tfidf, nm_train_y, xvalid_tfidf)\n",
    "    print (\"Logistic regression NearMiss(version= {0}), WordLevel TFIDF: \".format(sampler.version), accuracysm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A9nNg2irexcc"
   },
   "source": [
    "**Edited Nearest Neighbor (ENN)**\n",
    "\n",
    "ENN удаляет из большего класса элемент, если класс его ближайшего соседа отличается от его собственного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WFjd6PzjfWEU",
    "outputId": "fd494e3e-6621-4ab3-a445-932fe9fe4b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression {0}, WordLevel TFIDF:  0.5254691689008043\n"
     ]
    }
   ],
   "source": [
    "enn_xtrain_tfidf, enn_train_y = EditedNearestNeighbours().fit_sample(xtrain_tfidf, train_y)\n",
    "accuracy = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),enn_xtrain_tfidf, enn_train_y, xvalid_tfidf)\n",
    "print (\"Logistic regression {0}, WordLevel TFIDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VcHHV4jgZ50"
   },
   "source": [
    "Как вы поняли, при применении **Under-samplin**g техник новые данные не генерируются, в отличие от **Over-sampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CHYj7jW7z5q"
   },
   "source": [
    "# Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODhcR4G672lq"
   },
   "source": [
    "Итак, когда данных недостаточно или количество экземпляров в миноритарном классе очень мало применяется **Over-sampling**. \n",
    "\n",
    "При применении этой техники балансировка данных происходит за счет увеличения количества экземпляров в миноритарном классе. Новые элементы генерируются за счет: повторения, бутстрэппинга, SMOTE (Synthetic Minority Over-Sampling Technique) или ADASYN (Adaptive synthetic sampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ea9aYY4mxsqo"
   },
   "source": [
    "**Random Over-sampling**: случайным образом дублируются некоторые элементы из миноритарного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "t-6Ivm0ZOCOt",
    "outputId": "464d5085-d587-4523-d217-a142ad3e54b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression ROS, WordLevel TFIDF:  0.6431034482758621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Over Sampling\n",
    "ros = RandomOverSampler(random_state=777)\n",
    "ros_xtrain_tfidf, ros_train_y = ros.fit_sample(xtrain_tfidf, train_y)\n",
    "accuracyROS = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),ros_xtrain_tfidf, ros_train_y, xvalid_tfidf)\n",
    "print (\"Logistic regression ROS, WordLevel TFIDF: \", accuracyROS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXp1gpdDz5p5"
   },
   "source": [
    "**SMOTE Over-sampling**\n",
    "\n",
    "Алгоритм SMOTE основан на идее генерации некоторого количества искусственных примеров, которые были бы «похожи» на имеющиеся в миноритарном классе, но при этом не дублировали их.\n",
    "\n",
    "Для создания новой записи находят разность $d=X_b-X_a,$ где $ X_b, X_a -$ векторы признаков «соседних» примеров $a$ и $b$ из миноритарного класса. \n",
    "\n",
    "Их находят, используя алгоритм ближайшего соседа (*KNN*). В данном случае необходимо и достаточно для примера $b$ получить набор из $k$ соседей, из которого в дальнейшем будет выбрана запись $b$. Остальные шаги алгоритма *KNN* не требуются.\n",
    "\n",
    "Далее из $d$ путем умножения каждого его элемента на случайное число в интервале (0, 1) получают $\\hat{d}$. Вектор признаков нового примера вычисляется путем сложения $X_a$ и $\\hat{d}$. \n",
    "\n",
    "Алгоритм **SMOTE** позволяет задавать количество записей, которое необходимо искусственно сгенерировать. Степень сходства примеров $a$ и $b$ можно регулировать путем изменения значения $k$ (числа ближайших соседей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HWzqbIWsOEg1",
    "outputId": "8b09cf81-6226-4f8d-c1d7-8630537116f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression SMOTE, WordLevel TFIDF:  0.6519434628975266\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=777, ratio = 1.0)\n",
    "sm_xtrain_tfidf, sm_train_y = sm.fit_sample(xtrain_tfidf, train_y)\n",
    "accuracySMOTE = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),sm_xtrain_tfidf, sm_train_y, xvalid_tfidf)\n",
    "print (\"Logistic regression SMOTE, WordLevel TFIDF: \", accuracySMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gpJkvdb10Sg"
   },
   "source": [
    "Итак, по сравнению с **Random Over-sampling** разница небольшая.\n",
    "\n",
    "Проверьте результаты **Random Over-sampling** и **SMOTE Over-sampling** для реальных тестовых данных (*test_clean*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7V-VoCAO7qw0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Jz0o7k82YoX"
   },
   "source": [
    "Следующий алгоритм **ASMO: Adaptive synthetic minority oversampling**.\n",
    "\n",
    "\n",
    "\n",
    "Сгенерировать искусственные записи в пределах отдельных кластеров на основе всех классов. Для каждого примера миноритарного класса находят m ближайших соседей, и на основе них (также как в SMOTE) создаются новые записи.\n",
    "\n",
    "1.   Если для каждого $i$-ого примера миноритарного класса из $k$ ближайших соседей $g$ ($g\\leq k$) принадлежит к мажоритарному, то набор данных считается «рассеянным». В этом случае используют алгоритм **ASMO**, иначе применяют **SMOTE** (как правило, $g$ задают равным 20).\n",
    "2.   Используя только примеры миноритарного класса, выделить несколько кластеров (например, алгоритмом $k$-means).\n",
    "3.   Сгенерировать искусственные записи в пределах отдельных кластеров на основе всех классов. Для каждого примера миноритарного класса находят m ближайших соседей, и на основе них (также как в **SMOTE**) создаются новые записи.\n",
    "\n",
    "Такая модификация алгоритма **SMOTE** делает его более адаптивным к различным наборам данных с несбалансированными классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "mClRDnFM1weo",
    "outputId": "d8be5064-e79a-4c42-f3d7-be76ad8be2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression ADASYN, WordLevel TFIDF:  0.6495726495726495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "ad = ADASYN(random_state=777, ratio = 1.0)\n",
    "ad_xtrain_tfidf, ad_train_y = ad.fit_sample(xtrain_tfidf, train_y)\n",
    "accuracyADASYN = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),ad_xtrain_tfidf, ad_train_y, xvalid_tfidf)\n",
    "print (\"Logistic regression ADASYN, WordLevel TFIDF: \", accuracyADASYN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHRcvIRP4fx7"
   },
   "source": [
    "И опять проверим на реальных тестовых примерах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTzMbjvnRyFD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "br9FjH077ix0"
   },
   "source": [
    "# Комбинация **Under-** и **Over-sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-RCI42f42Hi"
   },
   "source": [
    "В *imblearn* реализованы две возможные комбинации:\n",
    "\n",
    "\n",
    "1.   **SMOTE** + **ENN**\n",
    "2.   **SMOTE** + **Tomek Link Removal** (Пара двух ближайших соседей, которые принадлежат разным классам называется *Tomek link*. Under-sampling заключается в удалении всех таких элементов из мажоритарного класса)\n",
    "\n",
    "Подробнее: https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.combine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3pg1YBvT4-xP",
    "outputId": "1e2d5061-d26e-4e4d-c3e6-689c054bc9b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression SMOTEENN:  0.487778381314503\n"
     ]
    }
   ],
   "source": [
    "se = SMOTEENN(random_state=42)\n",
    "se_xtrain_tfidf, se_train_y = se.fit_sample(xtrain_tfidf, train_y)\n",
    "accuracy = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),se_xtrain_tfidf, se_train_y, xvalid_tfidf)\n",
    "print (\"Logistic regression SMOTEENN: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Gd9dCEd5aDs"
   },
   "source": [
    "Первый метод сработал плохо. Оцените работу второго подхода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkZofkXo5RG2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
